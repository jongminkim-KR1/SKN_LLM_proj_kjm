"""
Ollama LLM í´ë¼ì´ì–¸íŠ¸
"""
import requests
from typing import Optional


class OllamaClient:
    def __init__(self, model: str = "EEVE-Korean-10.8B:latest", base_url: str = "http://localhost:11434"):
        self.model = model
        self.base_url = base_url
        self.chat_url = f"{base_url}/api/chat"

        server_type = "RunPod GPU" if "runpod" in base_url.lower() else "ë¡œì»¬"
        print(f"{'ğŸš€' if 'runpod' in base_url.lower() else 'ğŸ’»'} {server_type} Ollama ì„œë²„ ì‚¬ìš©: {base_url}")

    def generate(self, prompt: str, system_prompt: Optional[str] = None) -> str:
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        payload = {
            "model": self.model,
            "messages": messages,
            "stream": False,
            "options": {
                "temperature": 0.3,
                "top_p": 0.9,
                "num_predict": 500
            }
        }

        try:
            response = requests.post(self.chat_url, json=payload, timeout=120)
            response.raise_for_status()
            return response.json().get('message', {}).get('content', '').strip()
        except requests.exceptions.RequestException as e:
            print(f"Ollama API ì˜¤ë¥˜: {e}")
            return "[AI ì‘ë‹µ ì‹¤íŒ¨]"
